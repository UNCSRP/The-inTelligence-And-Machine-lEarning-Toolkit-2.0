# Script Management and Sharing in Github

This training module was developed by Dr. Kyle R. Roell and Dr. Julia E. Rager

Spring 2023


<!-- Data depositing (e.g., Dataverse example - what we like to do! Metadata file + main file, NCBI GEO, but mention others) -->

## Introduction to Training Module

Submitting data to pubically available repositories is an essential part of reproducible, transparent, and shareable research. There are many benefits to sharing and submiting your researching, such as:

+ Data will be efficiently 
+ Sharing
+ Reproducibility 
+ Archive / saved data online for easy access 
+ Increased awareness

And, while there are many benefits of submitting and sharing data publically, there are still many questions and concerns(?) that need to be addressed. Some of the most common questions are:

+ Which repository do I use?
+ How should I structure or format my data?
+ What is metadata and what does it look like?


In this training module, we will be answering some of these questions. We will be introducing some of the repositories that are commonly used to deposit data, how to set up meta data files, and how to organize example data in preparation for sharing. We will also be providing information provided by the various repositories on their best practices. Finally, although we are suggesting ways to set up meta data files, which repositories to use, etc., as with coding and data analysis, there are many ways to do this and our suggestions may or may not work for you and your research. 


## Data Repositories

There are many publically available repositories that we should consider when publishing data. Additionally, there are repositories that have been created for very specific datasets or fields of study. There are also many more generalist repositories that are suitable for submitting pretty much any type of data or reserach. For a list of some of the more commonly used repositories, [Nature](https://www.nature.com/sdata/policies/repositories#general) and [PLOS](https://journals.plos.org/plosone/s/recommended-repositories) have both published a list of recommended repositories. 

And while each repository and differnet type of data will have distinct requirements for data formatting, meta data style, etc., we will be trying to give a general guide for this. Additionally, we will be focusing on one of the more generalist repositories, [Dataverse](https://dataverse.org). However, we will also be give a brief introduction to a few other repositories, such as Gene Expression Omnibus, [GEO](https://www.ncbi.nlm.nih.gov/geo/), one of the premier repositories for genomic data. 


## Dataverse

Dataverse is an interesting repository option in that it allows for upload of basically any type of material, without any stringent requirements. And, while there are not many requirements for specific data types, there are still guidelines provided and helpful resources provided through the Dataverse organziation. In fact, there are very thorough, readable, and helpful user guides and best practices. 

<img src="Dataverse_initial_image.png" width="684"/>


The interesting thing about Dataverse is that while it was started at Harvard and the base Dataverse lives there, there are many instances of Dataverse that are specific to and supported by various institutions. For example, these training modules are being developed primariliy by faculty, staff, and students at the Univeristy of North Carolina at Chapel Hill. As such, our examples will be leveraging the [UNC Dataverse](https://dataverse.unc.edu). 

Before moving forward, it might be best to talk about what Dataverse is from a more general, intuitive perspective. One of the more easy ways to think about Dataverse is to intepret it as a folder system on your computer. A Dataverse is just a fancy folder that contains files, data, or datasets that are all related to some topic, project, etc. Let's now start talking more specifically about how to create your own "Dataverse", upload datasets, and what that means!


## What is a Dataverse?

Remember how we pointed out that a Dataverse is similar to a folder system on a computer? Well, here we are going to show you what that actually looks like. But first, one thing that I think confuses a lot of people when starting to work with dataverse, or at least confused us, was the term Dataverse is used for both the overarching repository as well as individual subsections (or folders) in which data is stored. For example, the UNC Dataverse is called a Dataverse, but to upload data, you need to upload it to a specific sub-Dataverse. This can get kind of confusing, what is the difference between the high level UNC Dataverse and smaller, sub-dataverses? Well, nothing, really. The UNC Dataverse is similar to a large folder that says, these are all the projects and reserach related to or contained within UNC. From there, we want to be more specific about where we store our reserach, so we are creating more sub-dataverse (folders) within that higher, overarching UNC Dataverse. 

As an example, using the UNC Dataverse, here we can see various sub-Dataverses that have been created as repositories for specific projects or types of data. 

<img src="UNC_Dataverse_Example.png" width="684"/>


As another example looking within a specific Dataverse, here we can see the Dataverse that hosts datasets and publications for Dr. Julia Rager's lab, the [Ragerlab-Dataverse](https://dataverse.unc.edu/dataverse/ragerlab).

<img src="RagerLab_example.png" width="684"/>

Within this Datavere, we can see various datasets produced by her lab. It is worth noting that the datasets may not necessarily be directly related to each other in terms of exact topic, for example, the Ragerlab-Dataverse hosts data pertaining to wildfire smoke exposure as well as chemical exposures and breast cancer. But they are all pertaining to experiements and analyses run within her specific lab. 

Now that we understand what a Dataverse is, let's take a look at how to create one (using the UNC Dataverse).


## Creating a Dataverse

Now, let's look at how to actually create a Dataverse. Fortunately, this process is pretty straighforward and simple to do. 

<img src="Add_dataverse.png" width="684"/>

+ Create a username and login
+ From the home Dataverse page, click "Add Data" and select "New Dataverse"
+ Fill in the information necessary

And, that it is. After creating your Dataverse, you will need to publish it, however, before it is accessible to the public. Note that you can actually create a Dataverse within another Dataverse (similar to a folder within a folder on your computer). This makes sense as even when you are creating a new Dataverse at the home, UNC Dataverse level, you are still technically creating a new Dataverse within an existing one (the large UNC Dataverse).

Here are some tips as you create your Dataverse:

+ Don't recreate a Dataverse that already exists
+ Choose a name that is specific, but general enough that it doesn't only pertain to one specific dataset
+ You can add more than one contact email, if necessary


## Creating a Dataset

Creating a dataset is basically creating a page for you data containing information about that data, a citation for the data (something valuable and somewhat unique to Dataverse), as well the place from where you data can be directly accessed or downloaded. Similar to creating a Dataverse, creating a dataset is a pretty straighforward task. First, however, you will need to decide under which Dataverse your data will live, as discussed previously with the Ragerlab-Dataverse example. 

<img src="Add_dataset.png" width="684"/>

To create a dataset:

+ Navigate to the Dataverse page under which your dataset will live
+ Click "Add Data" and then select "New Dataset"
+ Fill in the necessary information
+ Upload your data and metadata file (if applicable)


Now, you have a dataset within your Dataverse. Again, you will have to pubilsh the dataset for someone to have access to it. The easy part of using a more generalist repository like Dataverse, is that you do not have to have super strict data strcuture adherence. However, this means it is up to you to make sure your data is readable and useable. Let's now look at some general tips on structuring datasets and metadata files. 



## Dataset Structure

Before uploading your data to any data repository, it is important to structure your data efficiently and effectively, making it easy for others to navigate, understand, and utilize. While we have and will cover this in various sections throughout these training modules, here are some basic tips for data structure and organization. 

+ Keep all data for one participant or subject within one column (or row) of your dataset
  + Genomic data and other analytical assays tend to have subjects on columns and genes, expression, etc. as the rows
  + Descriptive and demographic data often tend to have subjects or participants as the rows and each descriptor variable (*** I cant think of the correct term right now for this besides like covariate or variable) as columns
+ Create succinct, descriptive variable names
  + For example, do not use something like "This Variable Contains Information Regrading Smoking Status", and instead just using something like, "Smoking_Status"
  + Be aware of using spacing, special characters, and capitalization within variable names 
+ Think about transforming data from wide to long format depending on your specific dataset and general conventions
+ Be sure to follow specific guidelines of repository when appropriate

The previous sections, "Excel Data Management", and "FAIR Data Management Practices" are also great resources to reference when thinking about organzing your data. 

An example of an organized, wide format dataset in Excel:

<img src="Excel_data.png" width="684"/>


## Dataset Metadata File

After having organized your data, it is important to have a metadata file for easy comprehension and utlization of your data for future researchers or anyone downloading your data. And while most repositories do capture some metadata on the dataset page (ex: descripton of data, upload date, contact information), there is generally little information about the data and variables. In this section, we hope to go over some general guidelines and tips to better annotate your data.

First, keep in mind, depending on the specific repository you are using, you may have to follow their metadata standards. But, if uploading to more generalist repository, this may be up to you to define. 

Generally, a metadata file consists of a set of descriptors for each variable in the data. If you are uploading data that contains many covariates or descriptive variables, it is essential that you provide a metadata file that describes these covariates. Both a description of the variable as well as any specific levels of any categorical or factor type variables. 

From the dataset presented previously, in section "Dataset Structure", here we present an example of the associated metadata:

<img src="Metadata.png" width="484"/>


## Concluding Remarks and Additional Resources


In this training module, we set out to express the importance of uploading data to repositories, demonstrate what the upload process may look like using a generalist repository (Dataverse), and give some examples and tips on structuring data for upload and creating metadata files. It is important to choose the approrpriate repository for your data based on your field of study and specifications of your work!

When trying to find a specific respository, here are a few potential resources (previously linked in section "Data Repositories"):

+ https://www.nature.com/sdata/policies/repositories#general
+ https://journals.plos.org/plosone/s/recommended-repositories 



## Test your Knowledge







